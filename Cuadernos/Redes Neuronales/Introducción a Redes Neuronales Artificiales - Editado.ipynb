{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a1a979aa-fb67-4567-a8c0-6f780c834127",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Redes neuronales artificiales\n",
    "\n",
    "Durante las últimas clases haremos una exploración sobre varias técnicas de aprendizaje profundo (deep learning) comenzando con las redes neuronales artificiales (ANN), en particular las redes neuronales Feedforward. \n",
    "\n",
    "Usaremos el framework Keras, que es una API de alto nivel además de Tensorflow. Keras se está volviendo muy popular recientemente debido a su simplicidad. Es muy fácil crear modelos complejos e iterar rápidamente. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0e9132b2-9194-4d87-9ed1-7070aaff0e02",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Introducción\n",
    "\n",
    "Las redes neuronales artificiales (ANN) son redes neuronales conformadas por varias capas de neuronas totalmente conectadas:\n",
    "\n",
    "![img1](https://raw.githubusercontent.com/Izainea/visualizacion/master/img/ANN1.png)\n",
    "\n",
    "\n",
    "Consisten en una capa de entrada, varias capas ocultas y una capa de salida. Cada nodo de una capa está conectado a todos los demás nodos de la siguiente capa. Representa lo que estudiamos hace un momento, el perceptrón:\n",
    "\n",
    "![img2](https://raw.githubusercontent.com/Izainea/visualizacion/master/img/ANN2.png)\n",
    "\n",
    "Después de que cada perceptrón aplica los pesos obtenidos y se tiene la salida después de aplicar la función de activación entonces cada salida se convierte en la entrada para la siguiente capa. Los cálculos fluyen el diagrama de izquierda a derecha y la salida final se calcula realizando este procedimiento para todos los nodos. \n",
    "\n",
    "El objetivo de esta red neuronal profunda es aprender los pesos asociados a cada flecha de la primera gráfica, en otras palabras, consiste en la estimación de las siguientes matrices:\n",
    "\n",
    "![img3](https://raw.githubusercontent.com/Izainea/visualizacion/master/img/ANN3.png)\n",
    "\n",
    "En ese sentido, aprovechando el gráfico anterior, entendemos que la salida, para la red representada en esa figura, se calcula de la siguiente forma:\n",
    "\n",
    "$$y=f(f(f(x\\cdot W_1)\\cdot W_2)\\cdot W_3)$$\n",
    "\n",
    "En este caso, todos los perceptrones tienen la misma función de activación $f$. El sesgo no esta incluido en la fórmula anterior, pero podemos ignorarlo mientras concebimos la intuición detrás de estas redes neuronales.\n",
    "\n",
    "## Backpropagation \n",
    "Hasta ahora hemos descrito el cálculo de la salida a partir de unos pesos estimados pero ¿Cómo estimamos estos pesos?, en otras palabras, ¿Cómo entrenamos esta red? \n",
    "\n",
    "El siguiente algoritmo describe este proceso:\n",
    "\n",
    "* Inicialice aleatoriamente los pesos de todos los nodos. \n",
    "\n",
    "* La salida final es el valor del último nodo. Compare la salida final con el objetivo real en los datos de entrenamiento y mida el error usando una función de pérdida (Loss function).\n",
    "\n",
    "* Realice un pase hacia atrás de derecha a izquierda y propague el error a cada nodo individual utilizando la propagación hacia atrás. * Calcule la contribución de cada peso al error y ajuste los pesos en consecuencia utilizando el descenso de gradiente. Propague los gradientes de error a partir de la última capa.\n",
    "\n",
    "La propagación hacia atrás con descenso de gradiente es el concepto fundamental detrás del entrenamiento de la red, en esencia buscamos minimizar el error y en ese sentido buscamos un valor mínimo de la función de pérdida. Los detalles matemáticos los omitiremos de esta explicación pero se pueden encontrar en este video:\n",
    "[![imgvid](https://img.youtube.com/vi/9OzLcgy1bjs/0.jpg)](https://www.youtube.com/watch?v=9OzLcgy1bjs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "70eb98ff-b213-4d01-998c-065e64cc5036",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## ¿Por qué funcionan las redes?\n",
    "\n",
    "La esencia de las redes neuronales, por lo menos en esta versión inicial, consiste en la posibilidad de proyectar-transformar los registros de entrada en un espacio con mayor dimensión, con eso el proceso de clasificación se hace más sencillo, el siguiente gráfico ilustra esta situación:\n",
    "\n",
    "![img4](https://raw.githubusercontent.com/Izainea/visualizacion/master/img/ANN4.png)\n",
    "\n",
    "La proyección a otra dimensión permitió que hicieramos una separación como la siguiente:\n",
    "\n",
    "![img5](https://raw.githubusercontent.com/Izainea/visualizacion/master/img/ANN5.png)\n",
    "\n",
    "En resumen, las ANN son modelos de aprendizaje profundo muy flexibles pero potentes, permiten estimar aproximaciones a cualquier función compleja. Su aumento de popularidad se ha debido a tres razones: trucos inteligentes que hicieron posible el entrenamiento de estos modelos, un gran aumento en la potencia computacional, especialmente GPU y entrenamiento distribuido, además de una gran cantidad de datos de entrenamiento.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ce42d98e-bc23-4a9c-ab2b-4ebf3eca71f7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Implementación en Python\n",
    "\n",
    "Vamos ahora a usar el framework `keras` para hacer algunas  clasificaciones. Iniciemos con lo que necesitamos para poder iniciar el desarrollo de los modelos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "925570e0-3999-406c-8e67-2f1d6762b545",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 200)\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.datasets import make_classification, make_moons, make_circles\n",
    "from sklearn.metrics import confusion_matrix, classification_report, mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils import shuffle\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization, Activation\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, KFold\n",
    "import keras.backend as K\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e549f442-ae03-46a3-920e-0218bfa19b41",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d5c3228f-316b-492a-b2dc-7769f4804207",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "`make_classification` es una función que nos permite simular un data set para clasificar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f764d05d-6da1-42f5-8ba5-e51cf84518d1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=1000, n_features=2, n_redundant=0, \n",
    "                           n_informative=2, random_state=2020, n_clusters_per_class=1)\n",
    "sns.scatterplot(x=X.T[0],y=X.T[1],hue=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "922ec0bc-5a49-4e53-b412-363e4c152b40",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Antes de usar `keras` veamos un clasificador lineal, la regresión logística, compararemos después como clasifica una red neuronal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9e171cf1-d8f7-43d3-9510-7f5b757409ca",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression(solver='liblinear')\n",
    "lr.fit(X, y)\n",
    "y_pred=lr.predict(X)\n",
    "sns.heatmap(confusion_matrix(y,y_pred),annot=True,fmt='.0f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e63c5413-d62b-45d8-b72c-2e5d5be7f3c2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(x=X.T[0],y=X.T[1],hue=y,style=y_pred)\n",
    "limits = np.array([-4, 4])\n",
    "boundary = -(lr.coef_[0][0] * limits + lr.intercept_[0]) / lr.coef_[0][1]\n",
    "plt.plot(limits, boundary, \"g-\", linewidth=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f4f2a928-1117-4e4f-97c7-1a26fc070866",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Ahora veamos que ocurre con `keras`, despleguemos el modelo de clasificación usando la sintaxis de keras, la documentación se puede encontrar aquí:\n",
    "[Documentación Keras](https://keras.io/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "21bc887f-fb5d-4eef-b630-7ca9717234b6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=1, input_shape=(2,), activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(x=X, y=y, verbose=1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1d872067-a952-4bcb-abd5-ae40910ff71c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3313c8d1-f227-49a8-90a0-3dbd0eae1c8a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "y_pred=model.predict_classes(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "17cdf26c-5c45-4612-8650-ca6572d8a1c6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "y_pred=(model.predict(X) > 0.5).astype(\"int32\")\n",
    "sns.heatmap(confusion_matrix(y,y_pred),annot=True,fmt='.0f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b9431002-7dab-44a0-9776-20d00e111c70",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ece05e51-6648-4654-95bd-cc057173f3c5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def plot_loss_accuracy(history):\n",
    "    historydf = pd.DataFrame(history.history, index=history.epoch)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    historydf.plot(ylim=(0, max(1, historydf.values.max())))\n",
    "    loss = history.history['loss'][-1]\n",
    "    acc = history.history['accuracy'][-1]\n",
    "    plt.title('Loss: %.3f, Accuracy: %.3f' % (loss, acc))\n",
    "plot_loss_accuracy(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5f688a5a-40dd-48bf-999e-0c0f5cf03c31",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=4, input_shape=(2,), activation='sigmoid'))\n",
    "model.add(Dense(units=4,  activation='sigmoid'))\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x=X, y=y, verbose=0, epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "59dc1ebe-b917-4f94-9119-a6d0754f474b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a295d0a5-77f6-425d-9d3b-007788817542",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "y_pred=(model.predict(X) > 0.5).astype(\"int32\")\n",
    "sns.heatmap(confusion_matrix(y,y_pred),annot=True,fmt='.0f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "33a9e4ac-010c-465d-a6d0-a8d2c4cd7fc1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plot_loss_accuracy(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "eb106f92-2248-4fe9-bcde-ae06df4101cd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(x=X.T[0],y=X.T[1],hue=y,style=y_pred.T[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "90de3792-db27-4cda-8ba2-cf484629ffcd",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Usaremos [El modelo secuencial](https://keras.io/guides/sequential_model/) de keras que nos permite construir redes neuronales profundas apilando capas una encima de otra.\n",
    "\n",
    "En el primer ejemplo se construye un modelo de regresión logística simple, todas las entradas están conectadas directamente al nodo de salida, sin capas ocultas. Es decir, calculamos $W$ para el modelo $y=f(x\\cdot W)$, con $f$ la función sigmoidea.\n",
    "\n",
    "\n",
    "\n",
    "En Keras no agregamos capas correspondientes a los nodos de entrada, solo lo hacemos para los nodos ocultos y de salida. En el primer modelo no tenemos capas ocultas, los nodos de entrada están conectados directamente al nodo de salida. Esto significa que nuestra definición de red neuronal en Keras solo tendrá una capa con un nodo, correspondiente al nodo de salida.\n",
    "\n",
    "Mientras que en el segundo hacemos una red como la que definimos en el gráfico de ejemplo, aquí la función de activación en todas las capas es la función sigmoide."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4f632b7d-3e33-4833-ac33-6e7512856a6c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "***Algunas anotaciones importantes en la creación del modelo secuencial en keras***\n",
    "\n",
    "La función Dense en Keras construye una capa de red neuronal completamente conectada, inicializando automáticamente los pesos como sesgos. Es una función muy útil que verá que se usa en todas partes. Los argumentos de la función se definen de la siguiente manera:\n",
    "\n",
    "* **units**: El primer argumento, que representa el número de nodos en esta capa.\n",
    "\n",
    "* **input_shape**: La primera capa en los modelos de Keras necesita especificar las dimensiones de entrada. Las capas posteriores no necesitan especificar este argumento.\n",
    "\n",
    "* **activation**: La función de activación.\n",
    "\n",
    "Posteriormente compilamos el modelo con la función `model.compile`. Esto crea el modelo de red neuronal especificando los detalles del proceso de aprendizaje. El modelo aún no se ha entrenado en este momento,  apenas declaramos el optimizador para usar y la función de pérdida para minimizar. Los argumentos para la función de compilación se definen de la siguiente manera:\n",
    "\n",
    "* **optimizer**: Optimizador a usar para minimizar la función de pérdida.\n",
    "* **loss**: La función de pérdida para minimizar.\n",
    "\n",
    "* **metrics**: sobre qué métrica informar las estadísticas del modelo, para problemas de clasificación, lo configuramos como exactitud.\n",
    "\n",
    "Finalmente compilamos con `model.history`, sus argumentos son:\n",
    "\n",
    "* **x**: Los datos de entrada, los definimos como X arriba. Contiene las coordenadas $x$ e $y$ de los puntos de entrada.\n",
    "* **y**: Se refiere a las etiquetas, en nuestro caso, la clase que estamos tratando de predecir: 0 o 1.\n",
    "* **verbose**: Imprime la pérdida y la precisión, configúrelo en 1 para ver el resultado.\n",
    "\n",
    "* **epochs**: Número de iteraciones para que la red repase todos los datos de entrenamiento. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3290176f-727f-462b-90c2-4a999d538985",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Una visualización del clasificador\n",
    "\n",
    "La siguiente función nos permite visualizar la forma en que clasifica el modelo, veamos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "298872cc-c4d3-48d2-94a7-3e69b84d7c37",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def plot_decision_boundary(func, X, y, figsize=(9, 6)):\n",
    "    amin, bmin = X.min(axis=0) - 0.1\n",
    "    amax, bmax = X.max(axis=0) + 0.1\n",
    "    hticks = np.linspace(amin, amax, 101)\n",
    "    vticks = np.linspace(bmin, bmax, 101)\n",
    "    \n",
    "    aa, bb = np.meshgrid(hticks, vticks)\n",
    "    ab = np.c_[aa.ravel(), bb.ravel()]\n",
    "    c = func(ab)\n",
    "    cc = c.reshape(aa.shape)\n",
    "\n",
    "    cm = plt.cm.RdBu\n",
    "    cm_bright = ListedColormap(['#FF0000', '#0000FF'])\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    contour = plt.contourf(aa, bb, cc, cmap=cm, alpha=0.8)\n",
    "    \n",
    "    ax_c = fig.colorbar(contour)\n",
    "    ax_c.set_label(\"$P(y = 1)$\")\n",
    "    ax_c.set_ticks([0, 0.25, 0.5, 0.75, 1])\n",
    "    \n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=cm_bright)\n",
    "    plt.xlim(amin, amax)\n",
    "    plt.ylim(bmin, bmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "25845500-13a8-49e4-9c21-87bde8d9d2a9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plot_decision_boundary(lambda x: model.predict(x), X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "77d2d0f1-b00a-4142-817f-c55bed93e3ec",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plot_decision_boundary(lambda x: lr.predict_proba(x).T[1], X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9bcd6504-f19e-4892-b232-21f8ab79803a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Datos no \"linealmente separables\"\n",
    "\n",
    "Usemos otra función de `sklearn` para simular datos más dificiles de separar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b334e075-affa-49de-a22b-01e4488bab59",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#make_moons\n",
    "X, y = make_moons(n_samples=1000, noise=0.05, random_state=2020)\n",
    "sns.scatterplot(x=X.T[0],y=X.T[1],hue=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e92f95d5-b775-4e05-a76e-fba83e293136",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=4, input_shape=(2,), activation='tanh'))\n",
    "model.add(Dense(units=4,  activation='tanh'))\n",
    "model.add(Dense(units=4,  activation='tanh'))\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x=X, y=y, verbose=0, epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "defa45eb-07da-4ab9-a645-af93a0fd3b81",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "044bb95b-10fe-47e5-9707-48813edc015f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "y_pred=(model.predict(X) > 0.5).astype(\"int32\")\n",
    "sns.heatmap(confusion_matrix(y,y_pred),annot=True,fmt='.0f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f220e4a7-2a48-482d-b32e-b71939605424",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plot_loss_accuracy(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "afd9f173-f6df-4782-a232-d406b501507d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(x=X.T[0],y=X.T[1],hue=y,style=y_pred.T[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9807b99c-8a97-4955-9b8a-a59a562466d2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plot_decision_boundary(lambda x: model.predict(x), X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cde19b74-4d65-4fec-88ae-96cf0d417b51",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#make_circles\n",
    "X, y = make_circles(n_samples=1000, noise=0.02, random_state=2020)\n",
    "sns.scatterplot(x=X.T[0],y=X.T[1],hue=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3824afa0-6d96-4c4e-a019-a555bb2c8309",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=4, input_shape=(2,), activation='tanh'))\n",
    "model.add(Dense(units=4,  activation='tanh'))\n",
    "model.add(Dense(units=4,  activation='tanh'))\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x=X, y=y, verbose=0, epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2f947193-36f3-4267-99a5-3ed72e426848",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bd52ead8-97c6-4273-8d75-2f2d965d69d6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "y_pred=(model.predict(X) > 0.5).astype(\"int32\")\n",
    "sns.heatmap(confusion_matrix(y,y_pred),annot=True,fmt='.0f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ba8a9ab1-a6dd-462b-9ab5-f61cab5d0d81",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plot_loss_accuracy(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e33b8a27-6685-40be-8bce-483dabaa2baa",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(x=X.T[0],y=X.T[1],hue=y,style=y_pred.T[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8054a6cc-5637-42d9-b404-6fdd2c942e6c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plot_decision_boundary(lambda x: model.predict(x), X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "987b816c-cb14-4046-82cf-48c046f6b4ca",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#make_multiclass\n",
    "def make_multiclass(N=500, D=2, K=3):\n",
    "    \"\"\"\n",
    "    N: number of points per class\n",
    "    D: dimensionality\n",
    "    K: number of classes\n",
    "    \"\"\"\n",
    "    np.random.seed(0)\n",
    "    X = np.zeros((N*K, D))\n",
    "    y = np.zeros(N*K)\n",
    "    for j in range(K):\n",
    "        ix = range(N*j, N*(j+1))\n",
    "        # radius\n",
    "        r = np.linspace(0.0,1,N)\n",
    "        # theta\n",
    "        t = np.linspace(j*4,(j+1)*4,N) + np.random.randn(N)*0.2\n",
    "        X[ix] = np.c_[r*np.sin(t), r*np.cos(t)]\n",
    "        y[ix] = j\n",
    "    fig = plt.figure(figsize=(6, 6))\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, s=40, cmap=plt.cm.RdYlBu, alpha=0.8)\n",
    "    plt.xlim([-1,1])\n",
    "    plt.ylim([-1,1])\n",
    "    return X, y\n",
    "X, y = make_multiclass(K=3)\n",
    "sns.scatterplot(x=X.T[0],y=X.T[1],hue=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6551f77a-1c32-4d2b-93c6-c3757719a346",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0b654350-0254-4ecf-bbd4-4ddc63d02064",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape=(2,), activation='tanh'))\n",
    "model.add(Dense(64,  activation='tanh'))\n",
    "model.add(Dense(32,  activation='tanh'))\n",
    "model.add(Dense(3,  activation='softmax'))\n",
    "model.compile('adam', 'categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "y_cat = to_categorical(y)\n",
    "history = model.fit(X, y_cat, verbose=0, epochs=20)\n",
    "plot_loss_accuracy(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "22fe51a5-3c79-4e66-a1e9-971277116a07",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "17c2c7d0-8b05-4f7c-9c5e-fc877488afd9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def plot_multiclass_decision_boundary(model, X, y):\n",
    "    x_min, x_max = X[:, 0].min() - 0.1, X[:, 0].max() + 0.1\n",
    "    y_min, y_max = X[:, 1].min() - 0.1, X[:, 1].max() + 0.1\n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 101), np.linspace(y_min, y_max, 101))\n",
    "    cmap = ListedColormap(['#FF0000', '#00FF00', '#0000FF'])\n",
    "\n",
    "    Z = model.predict_classes(np.c_[xx.ravel(), yy.ravel()], verbose=0)\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    plt.contourf(xx, yy, Z, cmap=plt.cm.Spectral, alpha=0.8)\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, s=40, cmap=plt.cm.RdYlBu)\n",
    "    plt.xlim(xx.min(), xx.max())\n",
    "    plt.ylim(yy.min(), yy.max())\n",
    "plot_multiclass_decision_boundary(model, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "44966522-4473-44aa-b9b0-32ca6e73fef9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plot_loss_accuracy(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1d69a2ab-f633-4789-a30b-9fc2b25cc324",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(x=X.T[0],y=X.T[1],hue=y,style=y_pred.T[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "35e2ce27-0283-4200-a690-f16064494e9a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**Ejercicio**\n",
    "\n",
    "Implemente los tres modelos de clasificación expuestos en esta clase y concluya respecto a las soluciones obtenidas."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {},
   "notebookName": "Introducción a Redes Neuronales Artificiales - Editado",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
